{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile RV measurements for all stars\n",
    "I will use the MultiNest output to recreate the MCMC chains for primary star RV, and use the cross-correlation functions to measure the companion rv (where applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Fitters\n",
    "import h5py\n",
    "import glob\n",
    "import os\n",
    "import HelperFunctions\n",
    "from astropy.io import fits\n",
    "import pandas as pd\n",
    "\n",
    "home = os.environ['HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find all the base directories for each instrument\n",
    "instrument_dirs = dict(TS23='{}/School/Research/McDonaldData'.format(home),\n",
    "                       CHIRON='{}/School/Research/CHIRON_data'.format(home),\n",
    "                       HRS='{}/School/Research/HET_data'.format(home),\n",
    "                       IGRINS='{}/School/Research/IGRINS_data'.format(home))\n",
    "basedirs = {inst: [n[:-4] for n in glob.glob('{}/RVFitter_flattened/*-.txt'.format(instrument_dirs[inst]))] for inst in instrument_dirs.keys()}\n",
    "\n",
    "# Collect the model files\n",
    "model_files = dict(TS23='/Volumes/DATADRIVE/Kurucz_Grid/TS23_grid_air.hdf5',\n",
    "                   HRS='/Volumes/DATADRIVE/Kurucz_Grid/HRS_grid_full.hdf5',\n",
    "                   CHIRON='/Volumes/DATADRIVE/Kurucz_Grid/CHIRON_grid_air.hdf5',\n",
    "                   IGRINS='/Volumes/DATADRIVE/Kurucz_Grid/IGRINS_grid_air.hdf5')\n",
    "\n",
    "# Get the flatten-fit information\n",
    "df_list = []\n",
    "for instrument in instrument_dirs.keys():\n",
    "    fname = '{}/Flatten.log'.format(instrument_dirs[instrument])\n",
    "    df = pd.read_csv(fname, header=None, names=['fname', 'star', 'date', 'teff', 'logg', 'rv'])\n",
    "    df.fname = df.fname.map(lambda s: '{}/{}'.format(instrument_dirs[instrument], s))\n",
    "    df.date = df.date.map(lambda s: s.replace('-', ''))\n",
    "    df['Instrument'] = instrument\n",
    "    df_list.append(df.copy())\n",
    "\n",
    "flatten_df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP100881_20130807-')\n",
      "('HIP 100881', '20130807')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP101589_20130605-')\n",
      "('HIP 101589', '20130605')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP101867_20130716-')\n",
      "('HIP 101867', '20130716')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP10320_20130828-')\n",
      "('HIP 10320', '20130828')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP104019_20130701-')\n",
      "('HIP 104019', '20130701')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP104139_20130605-')\n",
      "('HIP 104139', '20130605')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP105140_20130712-')\n",
      "('HIP 105140', '20130712')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP106786_20140517-')\n",
      "('HIP 106786', '20140517')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP107517_20140804-')\n",
      "('HIP 107517', '20140804')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP107608_20140511-')\n",
      "('HIP 107608', '20140511')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP108294_20140513-')\n",
      "('HIP 108294', '20140513')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP109139_20130604-')\n",
      "('HIP 109139', '20130604')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP109139_20130820-')\n",
      "('HIP 109139', '20130820')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP110838_20130908-')\n",
      "('HIP 110838', '20130908')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP112029_20130714-')\n",
      "('HIP 112029', '20130714')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP115115_20140520-')\n",
      "('HIP 115115', '20140520')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP116247_20130620-')\n",
      "('HIP 116247', '20130620')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP116971_20130714-')\n",
      "('HIP 116971', '20130714')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP116971_20130920-')\n",
      "('HIP 116971', '20130920')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP116971_20140731-')\n",
      "('HIP 116971', '20140731')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP117089_20130809-')\n",
      "('HIP 117089', '20130809')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP117452_20130626-')\n",
      "('HIP 117452', '20130626')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP118121_20140518-')\n",
      "('HIP 118121', '20140518')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP1191_20130917-')\n",
      "('HIP 1191', '20130917')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP1647_20130806-')\n",
      "('HIP 1647', '20130806')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP16611_20130818-')\n",
      "('HIP 16611', '20130818')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP17457_20130827-')\n",
      "('HIP 17457', '20130827')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP17563_20130903-')\n",
      "('HIP 17563', '20130903')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP18788_20130831-')\n",
      "('HIP 18788', '20130831')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP20264_20140302-')\n",
      "('HIP 20264', '20140302')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP20507_20140302-')\n",
      "('HIP 20507', '20140302')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP22913_20131020-')\n",
      "('HIP 22913', '20131020')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP22958_20130916-')\n",
      "('HIP 22958', '20130916')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP23362_20130913-')\n",
      "('HIP 23362', '20130913')\n",
      "Determine Chunk Log: Wl is 262144\n",
      "('CHIRON', '/Users/kgulliks/School/Research/CHIRON_data/RVFitter_flattened/HIP2381_20140805-')\n",
      "('HIP 2381', '20140805')\n",
      "Determine Chunk Log: Wl is 262144"
     ]
    }
   ],
   "source": [
    "# Get the MCMC chains, and store them in an HDF5 file.\n",
    "\n",
    "with h5py.File('RV_data.h5', 'w') as outfile:\n",
    "    for instrument in basedirs.keys():\n",
    "    #for instrument in ['CHIRON']:\n",
    "        inst_grp = outfile.require_group(instrument)\n",
    "        for basename in basedirs[instrument]:\n",
    "            print(instrument, basename)\n",
    "            # Get the star name and observation date from the filename\n",
    "            starname, date = os.path.basename(basename).split('_')\n",
    "            date = date[:-1]\n",
    "            if starname.startswith('HIP'):\n",
    "                starname = 'HIP {}'.format(starname[3:])\n",
    "            elif starname.startswith('HR'):\n",
    "                starname = 'HR {}'.format(starname[2:])\n",
    "            elif starname.startswith('ADS'):\n",
    "                starname = 'ADS {}'.format(starname[3:])\n",
    "            else:\n",
    "                print(\"Weird starname: {}\".format(starname))\n",
    "                continue\n",
    "            print(starname, date)\n",
    "            \n",
    "            # Get the path to the original fits file \n",
    "            star_data = flatten_df.loc[(flatten_df.star == starname) & \n",
    "                                       (flatten_df.date == date) & \n",
    "                                       (flatten_df.Instrument == instrument)]\n",
    "            filename = star_data.fname.item()\n",
    "            teff = star_data.teff.item()\n",
    "            logg = star_data.logg.item()\n",
    "            feh = 0.0\n",
    "            orders = HelperFunctions.ReadExtensionFits(filename)\n",
    "\n",
    "            # Set up the fitter\n",
    "            fitter = Fitters.RVFitter(orders, model_library=model_files[instrument],\n",
    "                                      T=teff, logg=logg, feh=feh)\n",
    "\n",
    "            # Fit (these are already fit, so this just gets the MCMC chains)\n",
    "            fitter.fit(backend='multinest', n_live_points=1000, basename=basename, overwrite=False, init_MPI=False)\n",
    "            \n",
    "            # Output to the HDF5 file\n",
    "            star_grp = inst_grp.require_group(starname)\n",
    "            dataset = star_grp.create_dataset(date, data=fitter.samples.values, maxshape=(None, 4))\n",
    "            \n",
    "            # Set attributes to summary values (so I don't need to read in the data if I only care about mean values)\n",
    "            dataset.attrs['column_names'] = list(fitter.samples.columns)\n",
    "            dataset.attrs['Teff'] = teff\n",
    "            dataset.attrs['logg'] = logg\n",
    "            dataset.attrs['rv'] = fitter.samples.RV.mean()\n",
    "            dataset.attrs['rv_err'] = fitter.samples.RV.std()\n",
    "            dataset.attrs['vsini'] = fitter.samples.vsini.mean()\n",
    "            dataset.attrs['vsini_err'] = fitter.samples.vsini.std()\n",
    "            dataset.attrs['epsilon'] = fitter.samples.epsilon.mean()\n",
    "            dataset.attrs['epsilon_err'] = fitter.samples.epsilon.std()\n",
    "            dataset.attrs['path'] = filename.replace(home, '~')\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
